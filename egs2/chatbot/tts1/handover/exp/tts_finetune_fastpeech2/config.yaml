config: conf/tuning/train_gst+xvector_conformer_fastspeech2.yaml
print_config: false
log_level: INFO
dry_run: false
iterator_type: sequence
output_dir: exp/tts_finetune_fastpeech2
ngpu: 1
seed: 0
num_workers: 1
num_att_plot: 3
dist_backend: nccl
dist_init_method: env://
dist_world_size: null
dist_rank: null
local_rank: 0
dist_master_addr: null
dist_master_port: null
dist_launcher: null
multiprocessing_distributed: false
unused_parameters: false
sharded_ddp: false
cudnn_enabled: true
cudnn_benchmark: false
cudnn_deterministic: true
collect_stats: false
write_collected_feats: false
max_epoch: 30
patience: null
val_scheduler_criterion:
- valid
- loss
early_stopping_criterion:
- valid
- loss
- min
best_model_criterion:
-   - valid
    - loss
    - min
-   - train
    - loss
    - min
keep_nbest_models: 5
nbest_averaging_interval: 0
grad_clip: 1.0
grad_clip_type: 2.0
grad_noise: false
accum_grad: 1
no_forward_run: false
resume: true
train_dtype: float32
use_amp: false
log_interval: null
use_matplotlib: true
use_tensorboard: true
create_graph_in_tensorboard: false
use_wandb: false
wandb_project: null
wandb_id: null
wandb_entity: null
wandb_name: null
wandb_model_log_interval: -1
detect_anomaly: false
pretrain_path: null
init_param:
- ../../aishell3/tts1/exp/tts_train_gst+xvector_conformer_fastspeech2_raw_phn_pypinyin_g2p_phone/train.loss.ave_5best.pth:tts:tts
ignore_init_mismatch: false
freeze_param: []
num_iters_per_epoch: 500
batch_size: 50
valid_batch_size: null
batch_bins: 1000000
valid_batch_bins: null
train_shape_file:
- exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/train/text_shape.phn
- exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/train/speech_shape
valid_shape_file:
- exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/valid/text_shape.phn
- exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/valid/speech_shape
batch_type: sorted
valid_batch_type: null
fold_length:
- 150
- 240000
sort_in_batch: descending
sort_batch: descending
multiple_iterator: false
chunk_length: 500
chunk_shift_ratio: 0.5
num_cache_chunks: 1024
train_data_path_and_name_and_type:
-   - dump/raw/train_no_dev_test/text
    - text
    - text
-   - exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/decode_use_teacher_forcingtrue_train.loss.ave//train_no_dev_test/durations
    - durations
    - text_int
-   - dump/raw/train_no_dev_test/wav.scp
    - speech
    - sound
-   - exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/train/collect_feats/pitch.scp
    - pitch
    - npy
-   - exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/train/collect_feats/energy.scp
    - energy
    - npy
-   - dump/xvector/train_no_dev_test/xvector.scp
    - spembs
    - kaldi_ark
valid_data_path_and_name_and_type:
-   - dump/raw/dev/text
    - text
    - text
-   - exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/decode_use_teacher_forcingtrue_train.loss.ave//dev/durations
    - durations
    - text_int
-   - dump/raw/dev/wav.scp
    - speech
    - sound
-   - exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/valid/collect_feats/pitch.scp
    - pitch
    - npy
-   - exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/valid/collect_feats/energy.scp
    - energy
    - npy
-   - dump/xvector/dev/xvector.scp
    - spembs
    - kaldi_ark
allow_variable_data_keys: false
max_cache_size: 0.0
max_cache_fd: 32
valid_max_cache_size: null
optim: adam
optim_conf:
    lr: 1.0
scheduler: noamlr
scheduler_conf:
    model_size: 384
    warmup_steps: 4000
token_list:
- <blank>
- <unk>
- d
- sh
- j
- i4
- zh
- l
- x
- e
- b
- g
- i1
- h
- q
- m
- t
- i2
- u4
- z
- ch
- i3
- f
- s
- n
- iou3
- r
- ian4
- ong1
- uei4
- e4
- en2
- ai4
- k
- ing2
- a1
- uo3
- u3
- ao4
- p
- an1
- eng2
- e2
- in1
- c
- ai2
- an4
- ian2
- u2
- ang4
- ian1
- ai3
- ing1
- ao3
- uo4
- ian3
- ing4
- ü4
- ang1
- u1
- iao4
- eng1
- iou4
- a4
- üan2
- ie4
- ou4
- er4
- en1
- ong2
- e1
- an3
- ei4
- uo2
- ou3
- ang2
- iang4
- ou1
- ang3
- an2
- eng4
- ong4
- uan4
- a3
- ia4
- ia1
- iao1
- iang1
- iou2
- uo1
- ei3
- iao3
- in4
- e3
- ü3
- iang3
- uei2
- en3
- uan1
- ie3
- ao1
- ai1
- üe4
- ü2
- ing3
- en4
- uei1
- er2
- uan3
- ü1
- in3
- en
- üe2
- ie2
- ei2
- ua4
- uan2
- in2
- a2
- ie1
- iang2
- ou2
- ong3
- uang3
- eng3
- uen1
- uai4
- ün4
- uang4
- uei3
- uen2
- uen4
- i
- iong4
- v3
- iao2
- üan4
- uang1
- ei1
- o2
- iou1
- uang2
- a
- ao2
- o1
- ua2
- uen3
- ua1
- v4
- üan3
- ün1
- üe1
- ün2
- o4
- er3
- iong3
- üan1
- ia3
- ia2
- iong1
- üe3
- ve4
- iong2
- uai2
- er
- ua3
- uai1
- ou
- ün3
- uai3
- ia
- uo
- o3
- v2
- ueng1
- o
- ei
- ua
- io1
- <sos/eos>
odim: null
model_conf: {}
use_preprocessor: true
token_type: phn
bpemodel: null
non_linguistic_symbols: null
cleaner: null
g2p: pypinyin_g2p_phone
feats_extract: fbank
feats_extract_conf:
    n_fft: 2048
    hop_length: 300
    win_length: 1200
    fs: 24000
    fmin: 80
    fmax: 7600
    n_mels: 80
normalize: global_mvn
normalize_conf:
    stats_file: exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/train/feats_stats.npz
tts: fastspeech2
tts_conf:
    adim: 384
    aheads: 2
    elayers: 4
    eunits: 1536
    dlayers: 4
    dunits: 1536
    positionwise_layer_type: conv1d
    positionwise_conv_kernel_size: 3
    duration_predictor_layers: 2
    duration_predictor_chans: 256
    duration_predictor_kernel_size: 3
    postnet_layers: 5
    postnet_filts: 5
    postnet_chans: 256
    use_masking: true
    encoder_normalize_before: true
    decoder_normalize_before: true
    reduction_factor: 1
    encoder_type: conformer
    decoder_type: conformer
    conformer_pos_enc_layer_type: rel_pos
    conformer_self_attn_layer_type: rel_selfattn
    conformer_activation_type: swish
    use_macaron_style_in_conformer: true
    use_cnn_in_conformer: true
    conformer_enc_kernel_size: 7
    conformer_dec_kernel_size: 31
    init_type: xavier_uniform
    transformer_enc_dropout_rate: 0.2
    transformer_enc_positional_dropout_rate: 0.2
    transformer_enc_attn_dropout_rate: 0.2
    transformer_dec_dropout_rate: 0.2
    transformer_dec_positional_dropout_rate: 0.2
    transformer_dec_attn_dropout_rate: 0.2
    pitch_predictor_layers: 5
    pitch_predictor_chans: 256
    pitch_predictor_kernel_size: 5
    pitch_predictor_dropout: 0.5
    pitch_embed_kernel_size: 1
    pitch_embed_dropout: 0.0
    stop_gradient_from_pitch_predictor: true
    energy_predictor_layers: 2
    energy_predictor_chans: 256
    energy_predictor_kernel_size: 3
    energy_predictor_dropout: 0.5
    energy_embed_kernel_size: 1
    energy_embed_dropout: 0.0
    stop_gradient_from_energy_predictor: false
    spk_embed_dim: 512
    spk_embed_integration_type: add
    use_gst: true
    gst_heads: 4
    gst_tokens: 16
pitch_extract: dio
pitch_extract_conf:
    fs: 24000
    n_fft: 2048
    hop_length: 300
    f0max: 400
    f0min: 80
    reduction_factor: 1
pitch_normalize: global_mvn
pitch_normalize_conf:
    stats_file: exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/train/pitch_stats.npz
energy_extract: energy
energy_extract_conf:
    fs: 24000
    n_fft: 2048
    hop_length: 300
    win_length: 1200
    reduction_factor: 1
energy_normalize: global_mvn
energy_normalize_conf:
    stats_file: exp/tts_finetune_tacotron2_raw_phn_chatbot_own_model/stats/train/energy_stats.npz
required:
- output_dir
- token_list
version: '202211'
distributed: false
